{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"t5-02.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Zfpg-n2gNgtB","colab_type":"text"},"source":["## T5 구현 과정 (2/2)\n","T5 모델 구현에 대한 설명 입니다.\n","\n","이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n","- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n","- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n","- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n","- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n","- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n","\n","\n","[Colab](https://colab.research.google.com/)에서 실행 했습니다."]},{"cell_type":"markdown","metadata":{"id":"b4fLocKzS8qH","colab_type":"text"},"source":["#### 0. Pip Install\n","필요한 패키지를 pip를 이용해서 설치합니다."]},{"cell_type":"code","metadata":{"id":"gP4qW5w6TAXe","colab_type":"code","outputId":"cf6f57fd-9c01-4b48-d479-72852e0cac5c","executionInfo":{"status":"ok","timestamp":1582368187255,"user_tz":-540,"elapsed":28667,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["!pip install sentencepiece\n","!pip install wget"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\r\u001b[K     |▎                               | 10kB 12.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 6.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 7.0MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.85\n","Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=e6a25da026f33947edcc73153385c40ae8e7758d46d8f60b791be74527c547d7\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XZs93qCwS_bM","colab_type":"text"},"source":["#### 1. Google Drive Mount\n","Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n","1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n","2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n","\n","학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."]},{"cell_type":"code","metadata":{"id":"1XR4LcDdNfnW","colab_type":"code","outputId":"d78ec3c2-2f63-4af6-bc5e-2394f7784d8a","executionInfo":{"status":"ok","timestamp":1582368245190,"user_tz":-540,"elapsed":86593,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n","data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FMgpP6fjTJF8","colab_type":"text"},"source":["#### 2. Imports"]},{"cell_type":"code","metadata":{"id":"KRgT80wpTJiO","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import json\n","import pandas as pd\n","from IPython.display import display\n","from tqdm import tqdm, tqdm_notebook, trange\n","import sentencepiece as spm\n","import wget\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRrdaSJ_TNAf","colab_type":"text"},"source":["#### 3. 폴더의 목록을 확인\n","Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."]},{"cell_type":"code","metadata":{"id":"QfWB9L0_TQlP","colab_type":"code","outputId":"d3d7ac1a-0dfd-4a0c-a9bb-3c2f432f4792","executionInfo":{"status":"ok","timestamp":1582368252087,"user_tz":-540,"elapsed":6880,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["for f in os.listdir(data_dir):\n","  print(f)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["kowiki.csv.gz\n","kowiki.model\n","kowiki.vocab\n","ratings_train.txt\n","ratings_test.txt\n","ratings_train.json\n","ratings_test.json\n","kowiki.txt\n","kowiki_gpt.json\n","save_gpt_pretrain.pth\n","kowiki_bert_0.json\n","save_bert_pretrain.pth\n","kowiki_t5.model\n","kowiki_t5.vocab\n","kowiki_t5_0.json\n","save_t5_pretrain.pth\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yUOwhKMyTXNQ","colab_type":"text"},"source":["#### 4. Vocab 및 입력\n","\n","[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."]},{"cell_type":"code","metadata":{"id":"1LX6VgIkTaKV","colab_type":"code","outputId":"79b07054-6ed5-4ae0-f5b5-256aa96f7e34","executionInfo":{"status":"ok","timestamp":1582368491073,"user_tz":-540,"elapsed":1637,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# vocab loading\n","vocab_file = f\"{data_dir}/kowiki_t5.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"LMgziU4ATcyN","colab_type":"text"},"source":["#### 5. Config\n","\n","모델에 설정 값을 전달하기 위한 config를 만듭니다."]},{"cell_type":"code","metadata":{"id":"GDcRg9V0Tdc1","colab_type":"code","colab":{}},"source":["\"\"\" configuration json을 읽어들이는 class \"\"\"\n","class Config(dict): \n","    __getattr__ = dict.__getitem__\n","    __setattr__ = dict.__setitem__\n","\n","    @classmethod\n","    def load(cls, file):\n","        with open(file, 'r') as f:\n","            config = json.loads(f.read())\n","            return Config(config)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUztpEf6Tfx1","colab_type":"code","outputId":"f4b2333e-619b-498c-996b-c2c94ac0b1f6","executionInfo":{"status":"ok","timestamp":1582368275112,"user_tz":-540,"elapsed":942,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["config = Config({\n","    \"n_vocab\": len(vocab),\n","    \"n_seq\": 256,\n","    \"n_layer\": 6,\n","    \"d_hidn\": 256,\n","    \"i_pad\": 0,\n","    \"d_ff\": 1024,\n","    \"n_head\": 4,\n","    \"d_head\": 64,\n","    \"dropout\": 0.1,\n","    \"layer_norm_epsilon\": 1e-12\n","})\n","print(config)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j93X24LtTijG","colab_type":"text"},"source":["#### 6. T5\n","\n","T5 Class 및 함수 입니다."]},{"cell_type":"code","metadata":{"id":"z_41WubQUImx","colab_type":"code","colab":{}},"source":["\"\"\" attention pad mask \"\"\"\n","def get_attn_pad_mask(seq_q, seq_k, i_pad):\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n","    return pad_attn_mask\n","\n","\n","\"\"\" attention decoder mask \"\"\"\n","def get_attn_decoder_mask(seq):\n","    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n","    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n","    return subsequent_mask\n","\n","\n","\"\"\" scale dot product attention \"\"\"\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.scale = 1 / (self.config.d_head ** 0.5)\n","        self.num_buckets = 32\n","        self.relative_attention_bias = torch.nn.Embedding(self.num_buckets, self.config.n_head)\n","    \n","    def forward(self, Q, K, V, attn_mask, bidirectional=True):\n","        qlen, klen = Q.size(-2), K.size(-2)\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n","        # (1, n_head, n_q_seq, n_k_seq)\n","        position_bias = self.compute_bias(qlen, klen, bidirectional=bidirectional)\n","        scores += position_bias\n","        scores.masked_fill_(attn_mask, -1e9)\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_prob = nn.Softmax(dim=-1)(scores)\n","        attn_prob = self.dropout(attn_prob)\n","        # (bs, n_head, n_q_seq, d_v)\n","        context = torch.matmul(attn_prob, V)\n","        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n","        return context, attn_prob\n","    \n","    def compute_bias(self, qlen, klen, bidirectional=True):\n","        context_position = torch.arange(qlen, dtype=torch.long)[:, None]\n","        memory_position = torch.arange(klen, dtype=torch.long)[None, :]\n","        # (qlen, klen)\n","        relative_position = memory_position - context_position\n","        # (qlen, klen)\n","        rp_bucket = self._relative_position_bucket(\n","            relative_position,  # shape (qlen, klen)\n","            num_buckets=self.num_buckets,\n","            bidirectional=bidirectional\n","        )\n","        # (qlen, klen)\n","        rp_bucket = rp_bucket.to(self.relative_attention_bias.weight.device)\n","        # (qlen, klen, n_head)\n","        values = self.relative_attention_bias(rp_bucket)\n","        # (1, n_head, qlen, klen)\n","        values = values.permute([2, 0, 1]).unsqueeze(0)\n","        return values\n","\n","    def _relative_position_bucket(self, relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n","        ret = 0\n","        n = -relative_position\n","        if bidirectional:\n","            num_buckets //= 2\n","            ret += (n < 0).to(torch.long) * num_buckets  # mtf.to_int32(mtf.less(n, 0)) * num_buckets\n","            n = torch.abs(n)\n","        else:\n","            n = torch.max(n, torch.zeros_like(n))\n","\n","        # half of the buckets are for exact increments in positions\n","        max_exact = num_buckets // 2\n","        is_small = n < max_exact\n","\n","        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n","        val_if_large = max_exact + (\n","                torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n","        ).to(torch.long)\n","        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n","\n","        ret += torch.where(is_small, n, val_if_large)\n","        return ret\n","\n","\n","\"\"\" multi head attention \"\"\"\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n","        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n","        self.dropout = nn.Dropout(config.dropout)\n","    \n","    def forward(self, Q, K, V, attn_mask, bidirectional=False):\n","        batch_size = Q.size(0)\n","        # (bs, n_head, n_q_seq, d_head)\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_k_seq, d_head)\n","        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_v_seq, d_head)\n","        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n","\n","        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask, bidirectional=bidirectional)\n","        # (bs, n_head, n_q_seq, h_head * d_head)\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n","        # (bs, n_head, n_q_seq, e_embd)\n","        output = self.linear(context)\n","        output = self.dropout(output)\n","        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n","        return output, attn_prob\n","\n","\n","\"\"\" feed forward \"\"\"\n","class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n","        self.active = F.gelu\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, inputs):\n","        # (bs, d_ff, n_seq)\n","        output = self.active(self.conv1(inputs.transpose(1, 2)))\n","        # (bs, n_seq, d_hidn)\n","        output = self.conv2(output).transpose(1, 2)\n","        output = self.dropout(output)\n","        # (bs, n_seq, d_hidn)\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WDXUeMKoULa2","colab_type":"code","colab":{}},"source":["\"\"\" encoder layer \"\"\"\n","class EncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","    \n","    def forward(self, inputs, attn_mask):\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n","        att_outputs = self.layer_norm1(inputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(att_outputs)\n","        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        return ffn_outputs, attn_prob\n","\n","\n","\"\"\" encoder \"\"\"\n","class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n","    \n","    def forward(self, enc_embd, enc_self_mask):\n","        # (bs, n_enc_seq, d_hidn)\n","        enc_outputs = enc_embd\n","\n","        attn_probs = []\n","        for layer in self.layers:\n","            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","            enc_outputs, attn_prob = layer(enc_outputs, enc_self_mask)\n","            attn_probs.append(attn_prob)\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n","        return enc_outputs, attn_probs\n","\n","\n","\"\"\" decoder layer \"\"\"\n","class DecoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.dec_enc_attn = MultiHeadAttention(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","    \n","    def forward(self, dec_inputs, enc_outputs, self_mask, ende_mask):\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n","        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_mask, bidirectional=False)\n","        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n","        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, ende_mask)\n","        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n","        # (bs, n_dec_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n","        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n","        return ffn_outputs, self_attn_prob, dec_enc_attn_prob\n","\n","\n","\"\"\" decoder \"\"\"\n","class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n","    \n","    def forward(self, dec_embd, enc_outputs, self_mask, ende_mask):\n","        # (bs, n_dec_seq, d_hidn)\n","        dec_outputs = dec_embd\n","\n","        self_attn_probs, dec_enc_attn_probs = [], []\n","        for layer in self.layers:\n","            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n","            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, self_mask, ende_mask)\n","            self_attn_probs.append(self_attn_prob)\n","            dec_enc_attn_probs.append(dec_enc_attn_prob)\n","        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n","        return dec_outputs, self_attn_probs, dec_enc_attn_probs\n","\n","\n","\"\"\" t5 \"\"\"\n","class T5(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.embedding = nn.Embedding(self.config.n_vocab, self.config.d_hidn)\n","        self.encoder = Encoder(self.config)\n","        self.decoder = Decoder(self.config)\n","\n","        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_vocab, bias=False)\n","        self.projection_lm.weight = self.embedding.weight\n","    \n","    def forward(self, enc_inputs, dec_inputs):\n","        enc_embd = self.embedding(enc_inputs)\n","        dec_embd = self.embedding(dec_inputs)\n","\n","        enc_self_mask = get_attn_pad_mask(enc_inputs, enc_inputs, self.config.i_pad)\n","        dec_self_mask = self.get_attn_dec_mask(dec_inputs)\n","        dec_ende_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n","\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n","        enc_outputs, enc_self_attn_probs = self.encoder(enc_embd, enc_self_mask)\n","        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_embd, enc_outputs, dec_self_mask, dec_ende_mask)\n","        # (bs, n_dec_seq, n_vocab)\n","        dec_outputs = self.projection_lm(dec_outputs)\n","        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n","    \n","    def get_attn_dec_mask(self, dec_inputs):\n","         # (bs, n_dec_seq, n_dec_seq)\n","        dec_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_ahead_mask = get_attn_decoder_mask(dec_inputs)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_self_mask = torch.gt((dec_pad_mask + dec_ahead_mask), 0)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        return dec_self_mask\n","\n","    def save(self, epoch, loss, path):\n","        torch.save({\n","            \"epoch\": epoch,\n","            \"loss\": loss,\n","            \"state_dict\": self.state_dict()\n","        }, path)\n","    \n","    def load(self, path):\n","        save = torch.load(path)\n","        self.load_state_dict(save[\"state_dict\"])\n","        return save[\"epoch\"], save[\"loss\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pZQyVfnJUcXH","colab_type":"text"},"source":["#### 7. Naver 영화 분류 모델"]},{"cell_type":"code","metadata":{"id":"KIu5UyLUUdMW","colab_type":"code","colab":{}},"source":["\"\"\" naver movie classfication \"\"\"\n","class MovieClassification(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.t5 = T5(self.config)\n","    \n","    def forward(self, enc_inputs, dec_inputs):\n","        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.t5(enc_inputs, dec_inputs)\n","        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L_DfRSm3Uzg3","colab_type":"text"},"source":["#### 8. 네이버 영화 분류 데이터\n","\n","T5를 위해 vocab을 새로 만들어서 학습 데이터도 새로 만들 었습니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"xbAbC56jglXe","colab_type":"code","colab":{}},"source":["\"\"\" train data 준비 \"\"\"\n","def prepare_train(vocab, infile, outfile):\n","    df = pd.read_csv(infile, sep=\"\\t\", engine=\"python\")\n","    with open(outfile, \"w\") as f:\n","        for index, row in df.iterrows():\n","            document = row[\"document\"]\n","            if type(document) != str:\n","                continue\n","            instance = { \"id\": row[\"id\"], \"doc\": vocab.encode_as_pieces(document), \"label\": row[\"label\"] }\n","            f.write(json.dumps(instance, ensure_ascii=False))\n","            f.write(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyUB5liAgzKr","colab_type":"code","colab":{}},"source":["prepare_train(vocab, f\"{data_dir}/ratings_train.txt\", f\"{data_dir}/ratings_train_t5.json\")\n","prepare_train(vocab, f\"{data_dir}/ratings_test.txt\", f\"{data_dir}/ratings_test_t5.json\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7F8q2PatU0KH","colab_type":"code","colab":{}},"source":["\"\"\" 정답 text \"\"\"\n","lable_map = {0: \"부\", 1: \"정\"}\n","\n","\"\"\" 영화 분류 데이터셋 \"\"\"\n","class MovieDataSet(torch.utils.data.Dataset):\n","    def __init__(self, vocab, infile, is_valid=False):\n","        self.vocab = vocab\n","        self.labels = []\n","        self.enc_inputs = []\n","        self.dec_inputs = []\n","\n","        line_cnt = 0\n","        with open(infile, \"r\") as f:\n","            for line in f:\n","                line_cnt += 1\n","\n","        with open(infile, \"r\") as f:\n","            for i, line in enumerate(tqdm(f, total=line_cnt, desc=\"Loading Dataset\", unit=\" lines\")):\n","                data = json.loads(line)\n","\n","                enc_input = vocab.encode_as_ids(\"감정분류:\") + [vocab.piece_to_id(p) for p in data[\"doc\"]]\n","                if is_valid:\n","                    label = vocab.encode_as_ids(lable_map[data[\"label\"]])\n","                    dec_input = [vocab.piece_to_id(\"[BOS]\")]\n","                else:\n","                    label = vocab.encode_as_ids(lable_map[data[\"label\"]]) + [vocab.piece_to_id(\"[EOS]\")]\n","                    dec_input = [vocab.piece_to_id(\"[BOS]\")] + vocab.encode_as_ids(lable_map[data[\"label\"]])\n","\n","                self.labels.append(label)\n","                self.enc_inputs.append(enc_input)\n","                self.dec_inputs.append(dec_input)\n","    \n","    def __len__(self):\n","        assert len(self.labels) == len(self.enc_inputs)\n","        assert len(self.labels) == len(self.dec_inputs)\n","        return len(self.labels)\n","    \n","    def __getitem__(self, item):\n","        return (torch.tensor(self.labels[item]),\n","                torch.tensor(self.enc_inputs[item]),\n","                torch.tensor(self.dec_inputs[item]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GIUF3NDiU9JY","colab_type":"code","colab":{}},"source":["\"\"\" movie data collate_fn \"\"\"\n","def movie_collate_fn(inputs):\n","    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n","\n","    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n","    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n","\n","    batch = [\n","        torch.stack(labels, dim=0),\n","        enc_inputs,\n","        dec_inputs,\n","    ]\n","    return batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7h4x5WAVE-Y","colab_type":"code","outputId":"5f02254c-98f5-4f1f-affb-9b6eac6d9618","executionInfo":{"status":"ok","timestamp":1582369915838,"user_tz":-540,"elapsed":10721,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\"\"\" 데이터 로더 \"\"\"\n","batch_size = 128\n","train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train_t5.json\")\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n","test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test_t5.json\", is_valid=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Loading Dataset: 100%|██████████| 149995/149995 [00:06<00:00, 21670.37 lines/s]\n","Loading Dataset: 100%|██████████| 49997/49997 [00:01<00:00, 25291.42 lines/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-ROkwVAZVMBq","colab_type":"text"},"source":["#### 9. 네이버 영화 분류 데이터 학습"]},{"cell_type":"code","metadata":{"id":"3uk8i_COVMqY","colab_type":"code","colab":{}},"source":["\"\"\" 모델 epoch 평가 \"\"\"\n","def eval_epoch(config, model, data_loader):\n","    matchs = []\n","    model.eval()\n","\n","    n_word_total = 0\n","    n_correct_total = 0\n","    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n","        for i, value in enumerate(data_loader):\n","            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n","\n","            outputs = model(enc_inputs, dec_inputs)\n","            logits = outputs[0]\n","            _, indices = logits.max(2)\n","\n","            match = torch.eq(indices, labels).detach()\n","            matchs.extend(match.cpu())\n","            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n","    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDuh_wmmVWSC","colab_type":"code","colab":{}},"source":["\"\"\" 모델 epoch 학습 \"\"\"\n","def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n","    losses = []\n","    model.train()\n","\n","    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n","        for i, value in enumerate(train_loader):\n","            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n","\n","            optimizer.zero_grad()\n","            outputs = model(enc_inputs, dec_inputs)\n","            logits = outputs[0]\n","\n","            loss = criterion(logits.view(-1, logits.size(2)), labels.view(-1))\n","\n","            loss_val = loss.item()\n","            losses.append(loss_val)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n","    return np.mean(losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8zkUfOmVjNo","colab_type":"code","outputId":"14b9e1b2-a4f9-4c16-f03d-dd6fa256913e","executionInfo":{"status":"ok","timestamp":1582377510886,"user_tz":-540,"elapsed":995,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(config)\n","\n","learning_rate = 5e-5\n","n_epoch = 5"],"execution_count":32,"outputs":[{"output_type":"stream","text":["{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wZhTd_zVo8Y","colab_type":"code","colab":{}},"source":["def train(model):\n","    model.to(config.device)\n","\n","    criterion_cls = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    best_epoch, best_loss, best_score = 0, 0, 0\n","    losses, scores = [], []\n","    for epoch in range(n_epoch):\n","        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n","        score = eval_epoch(config, model, test_loader)\n","\n","        losses.append(loss)\n","        scores.append(score)\n","\n","        if best_score < score:\n","            best_epoch, best_loss, best_score = epoch, loss, score\n","    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n","    return losses, scores"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ui2zgSlUVxDw","colab_type":"text"},"source":["###### Pretrain 없이 학습"]},{"cell_type":"code","metadata":{"id":"pojS0xVsVv_y","colab_type":"code","outputId":"c39be6c8-956c-4faf-ea11-2f4922466459","executionInfo":{"status":"ok","timestamp":1582379370975,"user_tz":-540,"elapsed":1857865,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["model = MovieClassification(config)\n","\n","losses_00, scores_00 = train(model)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Train(0): 100%|██████████| 1172/1172 [05:07<00:00,  3.72it/s, Loss: 0.244 (0.827)]\n","Valid: 100%|██████████| 391/391 [01:00<00:00,  4.63it/s, Acc: 0.771]\n","Train(1): 100%|██████████| 1172/1172 [05:06<00:00,  3.89it/s, Loss: 0.232 (0.253)]\n","Valid: 100%|██████████| 391/391 [01:02<00:00,  4.59it/s, Acc: 0.794]\n","Train(2): 100%|██████████| 1172/1172 [05:10<00:00,  4.05it/s, Loss: 0.235 (0.229)]\n","Valid: 100%|██████████| 391/391 [01:02<00:00,  4.76it/s, Acc: 0.812]\n","Train(3): 100%|██████████| 1172/1172 [05:10<00:00,  3.88it/s, Loss: 0.193 (0.214)]\n","Valid: 100%|██████████| 391/391 [01:02<00:00,  4.77it/s, Acc: 0.816]\n","Train(4): 100%|██████████| 1172/1172 [05:09<00:00,  3.75it/s, Loss: 0.192 (0.201)]\n","Valid: 100%|██████████| 391/391 [01:01<00:00,  4.84it/s, Acc: 0.814]\n"],"name":"stderr"},{"output_type":"stream","text":[">>>> epoch=3, loss=0.21405, socre=0.81623\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gJALhcUrV-5T","colab_type":"text"},"source":["###### Pretrain을 한 후 학습"]},{"cell_type":"code","metadata":{"id":"WvGZZyUBV2pI","colab_type":"code","outputId":"79a399b7-f760-48f8-f8ae-788447f773ec","executionInfo":{"status":"ok","timestamp":1582381220431,"user_tz":-540,"elapsed":3705378,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["model = MovieClassification(config)\n","\n","save_pretrain = f\"{data_dir}/save_t5_pretrain.pth\"\n","model.t5.load(save_pretrain)\n","\n","losses_20, scores_20 = train(model)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Train(0): 100%|██████████| 1172/1172 [05:11<00:00,  3.69it/s, Loss: 0.227 (0.288)]\n","Valid: 100%|██████████| 391/391 [01:01<00:00,  4.86it/s, Acc: 0.769]\n","Train(1): 100%|██████████| 1172/1172 [05:07<00:00,  3.93it/s, Loss: 0.261 (0.220)]\n","Valid: 100%|██████████| 391/391 [01:00<00:00,  4.68it/s, Acc: 0.813]\n","Train(2): 100%|██████████| 1172/1172 [05:06<00:00,  3.94it/s, Loss: 0.173 (0.204)]\n","Valid: 100%|██████████| 391/391 [01:00<00:00,  4.67it/s, Acc: 0.822]\n","Train(3): 100%|██████████| 1172/1172 [05:09<00:00,  3.78it/s, Loss: 0.205 (0.191)]\n","Valid: 100%|██████████| 391/391 [01:03<00:00,  4.86it/s, Acc: 0.828]\n","Train(4): 100%|██████████| 1172/1172 [05:07<00:00,  3.98it/s, Loss: 0.138 (0.181)]\n","Valid: 100%|██████████| 391/391 [01:00<00:00,  4.56it/s, Acc: 0.827]\n"],"name":"stderr"},{"output_type":"stream","text":[">>>> epoch=3, loss=0.19078, socre=0.82767\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C0_DtGYqWCvs","colab_type":"text"},"source":["#### 10. Result"]},{"cell_type":"code","metadata":{"id":"aZnPu0tgWIUI","colab_type":"code","outputId":"7ccc1f81-067c-46e1-f006-65d5dc19b9a3","executionInfo":{"status":"ok","timestamp":1582381452200,"user_tz":-540,"elapsed":1706,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAPlcSngbLljlB6NXjYz4mX-N6bF5SV9sRtuK55_qE=s64","userId":"02662570985009482782"}},"colab":{"base_uri":"https://localhost:8080/","height":468}},"source":["# table\n","data = {\n","    \"loss_00\": losses_00,\n","    \"socre_00\": scores_00,\n","    \"loss_20\": losses_20,\n","    \"socre_20\": scores_20,\n","}\n","df = pd.DataFrame(data)\n","display(df)\n","\n","# graph\n","plt.figure(figsize=[12, 4])\n","plt.plot(scores_00, label=\"score_00\")\n","plt.plot(scores_20, label=\"score_20\")\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Value')\n","plt.show()"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss_00</th>\n","      <th>socre_00</th>\n","      <th>loss_20</th>\n","      <th>socre_20</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.827442</td>\n","      <td>0.771186</td>\n","      <td>0.287530</td>\n","      <td>0.769306</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.252628</td>\n","      <td>0.793888</td>\n","      <td>0.220361</td>\n","      <td>0.812609</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.228660</td>\n","      <td>0.811849</td>\n","      <td>0.204462</td>\n","      <td>0.822269</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.214050</td>\n","      <td>0.816229</td>\n","      <td>0.190784</td>\n","      <td>0.827670</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.201390</td>\n","      <td>0.813929</td>\n","      <td>0.180830</td>\n","      <td>0.827170</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    loss_00  socre_00   loss_20  socre_20\n","0  0.827442  0.771186  0.287530  0.769306\n","1  0.252628  0.793888  0.220361  0.812609\n","2  0.228660  0.811849  0.204462  0.822269\n","3  0.214050  0.816229  0.190784  0.827670\n","4  0.201390  0.813929  0.180830  0.827170"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAtcAAAEICAYAAACUDtg6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 864x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}